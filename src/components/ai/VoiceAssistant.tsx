import React, { useState, useRef, useEffect } from 'react';
import { useTranslation } from 'react-i18next';
import { Mic, MicOff, Volume2, VolumeX, MessageCircle, Loader, Camera, SwitchCamera, Languages, Play, Pause } from 'lucide-react';
import Webcam from 'react-webcam';
import { geminiService } from '../../services/geminiService';

interface Message {
  id: string;
  type: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  audioUrl?: string;
  language?: string;
}

const VoiceAssistant: React.FC = () => {
  const { t, i18n } = useTranslation();
  const [messages, setMessages] = useState<Message[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [audioEnabled, setAudioEnabled] = useState(true);
  const [selectedLanguage, setSelectedLanguage] = useState('hi'); // Default to Hindi
  const [showCamera, setShowCamera] = useState(false);
  const [facingMode, setFacingMode] = useState<'user' | 'environment'>('environment');
  const [isPlaying, setIsPlaying] = useState<string | null>(null);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const webcamRef = useRef<Webcam>(null);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const synthRef = useRef<SpeechSynthesis | null>(null);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);

  const languages = [
    { code: 'hi', name: '‡§π‡§ø‡§Ç‡§¶‡•Ä', flag: 'üáÆüá≥' },
    { code: 'en', name: 'English', flag: 'üá∫üá∏' },
    { code: 'kn', name: '‡≤ï‡≤®‡≥ç‡≤®‡≤°', flag: 'üáÆüá≥' },
    { code: 'te', name: '‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å', flag: 'üáÆüá≥' },
    { code: 'ta', name: '‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç', flag: 'üáÆüá≥' },
    { code: 'mr', name: '‡§Æ‡§∞‡§æ‡§†‡•Ä', flag: 'üáÆüá≥' }
  ];

  useEffect(() => {
    // Initialize Speech Recognition
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
      recognitionRef.current = new SpeechRecognition();
      recognitionRef.current.continuous = false;
      recognitionRef.current.interimResults = false;
      recognitionRef.current.lang = getLanguageCode(selectedLanguage);
    }

    // Initialize Speech Synthesis
    if ('speechSynthesis' in window) {
      synthRef.current = window.speechSynthesis;
    }

    return () => {
      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
      }
    };
  }, [selectedLanguage]);

  const getLanguageCode = (lang: string) => {
    const langMap: { [key: string]: string } = {
      'hi': 'hi-IN',
      'en': 'en-US',
      'kn': 'kn-IN',
      'te': 'te-IN',
      'ta': 'ta-IN',
      'mr': 'mr-IN'
    };
    return langMap[lang] || 'hi-IN';
  };

  const getLanguageName = (code: string) => {
    const lang = languages.find(l => l.code === code);
    return lang ? lang.name : '‡§π‡§ø‡§Ç‡§¶‡•Ä';
  };

  const startVoiceRecording = async () => {
    if (!recognitionRef.current) {
      alert('Speech recognition not supported in this browser');
      return;
    }

    setIsRecording(true);
    setIsProcessing(false);

    recognitionRef.current.lang = getLanguageCode(selectedLanguage);
    
    recognitionRef.current.onresult = async (event) => {
      const transcript = event.results[0][0].transcript;
      await processVoiceQuery(transcript);
    };

    recognitionRef.current.onerror = (event) => {
      console.error('Speech recognition error:', event.error);
      setIsRecording(false);
      addMessage('assistant', 'Sorry, I couldn\'t understand. Please try again.', selectedLanguage);
    };

    recognitionRef.current.onend = () => {
      setIsRecording(false);
    };

    recognitionRef.current.start();
  };

  const stopVoiceRecording = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
    setIsRecording(false);
  };

  const processVoiceQuery = async (transcript: string) => {
    setIsProcessing(true);
    
    try {
      // Add user message
      addMessage('user', transcript, selectedLanguage);

      // Get AI response based on language
      const response = await getAIResponse(transcript, selectedLanguage);
      
      // Add assistant response
      const assistantMessage = addMessage('assistant', response, selectedLanguage);

      // Convert response to speech if audio is enabled
      if (audioEnabled) {
        await speakText(response, selectedLanguage, assistantMessage.id);
      }
    } catch (error) {
      console.error('Error processing voice query:', error);
      const errorMessage = getErrorMessage(selectedLanguage);
      addMessage('assistant', errorMessage, selectedLanguage);
    } finally {
      setIsProcessing(false);
    }
  };

  const getAIResponse = async (query: string, language: string): Promise<string> => {
    const languagePrompts = {
      'hi': `‡§Ü‡§™ ‡§è‡§ï ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§π‡•à‡§Ç‡•§ ‡§á‡§∏ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§¶‡•á‡§Ç: "${query}". ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§Ç‡•§`,
      'en': `You are an agricultural expert. Answer this question in English: "${query}". Provide practical advice for Indian farmers.`,
      'kn': `‡≤®‡≥Ä‡≤µ‡≥Å ‡≤ï‡≥É‡≤∑‡≤ø ‡≤§‡≤ú‡≥ç‡≤û‡≤∞‡≥Å. ‡≤à ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤ï‡≤®‡≥ç‡≤®‡≤°‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤â‡≤§‡≥ç‡≤§‡≤∞‡≤ø‡≤∏‡≤ø: "${query}". ‡≤≠‡≤æ‡≤∞‡≤§‡≥Ä‡≤Ø ‡≤∞‡≥à‡≤§‡≤∞‡≤ø‡≤ó‡≥Ü ‡≤™‡≥ç‡≤∞‡≤æ‡≤Ø‡≥ã‡≤ó‡≤ø‡≤ï ‡≤∏‡≤≤‡≤π‡≥Ü ‡≤®‡≥Ä‡≤°‡≤ø‡•§`,
      'te': `‡∞Æ‡±Ä‡∞∞‡±Å ‡∞µ‡±ç‡∞Ø‡∞µ‡∞∏‡∞æ‡∞Ø ‡∞®‡∞ø‡∞™‡±Å‡∞£‡±Å‡∞≤‡±Å. ‡∞à ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞ï‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø: "${query}". ‡∞≠‡∞æ‡∞∞‡∞§‡±Ä‡∞Ø ‡∞∞‡±à‡∞§‡±Å‡∞≤‡∞ï‡±Å ‡∞Ü‡∞ö‡∞∞‡∞£‡∞æ‡∞§‡±ç‡∞Æ‡∞ï ‡∞∏‡∞≤‡∞π‡∞æ ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø‡•§`,
      'ta': `‡Æ®‡ØÄ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æí‡Æ∞‡ØÅ ‡Æµ‡Æø‡Æµ‡Æö‡Ææ‡ÆØ ‡Æ®‡Æø‡Æ™‡ØÅ‡Æ£‡Æ∞‡Øç. ‡Æá‡Æ®‡Øç‡Æ§ ‡Æï‡Øá‡Æ≥‡Øç‡Æµ‡Æø‡Æï‡Øç‡Æï‡ØÅ ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Æø‡Æ≤‡Øç ‡Æ™‡Æ§‡Æø‡Æ≤‡Æ≥‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç: "${query}". ‡Æá‡Æ®‡Øç‡Æ§‡Æø‡ÆØ ‡Æµ‡Æø‡Æµ‡Æö‡Ææ‡ÆØ‡Æø‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æ®‡Æü‡Øà‡ÆÆ‡ØÅ‡Æ±‡Øà ‡ÆÜ‡Æ≤‡Øã‡Æö‡Æ©‡Øà ‡Æµ‡Æ¥‡Æô‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç‡•§`,
      'mr': `‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ï‡•É‡§∑‡•Ä ‡§§‡§ú‡•ç‡§û ‡§Ü‡§π‡§æ‡§§. ‡§Ø‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡§æ‡§ö‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§¶‡•ç‡§Ø‡§æ: "${query}". ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§∂‡•á‡§§‡§ï‡§±‡•ç‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§∏‡§≤‡•ç‡§≤‡§æ ‡§¶‡•ç‡§Ø‡§æ‡•§`
    };

    const prompt = languagePrompts[language as keyof typeof languagePrompts] || languagePrompts['hi'];
    return await geminiService.getCropAdvice(prompt);
  };

  const getErrorMessage = (language: string): string => {
    const errorMessages = {
      'hi': '‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§∏‡§Æ‡§ù ‡§®‡§π‡•Ä‡§Ç ‡§™‡§æ‡§Ø‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§',
      'en': 'Sorry, I couldn\'t understand. Please try again.',
      'kn': '‡≤ï‡≥ç‡≤∑‡≤Æ‡≤ø‡≤∏‡≤ø, ‡≤®‡≤®‡≤ó‡≥Ü ‡≤Ö‡≤∞‡≥ç‡≤•‡≤µ‡≤æ‡≤ó‡≤≤‡≤ø‡≤≤‡≥ç‡≤≤. ‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü ‡≤™‡≥ç‡≤∞‡≤Ø‡≤§‡≥ç‡≤®‡≤ø‡≤∏‡≤ø.',
      'te': '‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞®‡∞æ‡∞ï‡±Å ‡∞Ö‡∞∞‡±ç‡∞•‡∞Ç ‡∞ï‡∞æ‡∞≤‡±á‡∞¶‡±Å. ‡∞¶‡∞Ø‡∞ö‡±á‡∞∏‡∞ø ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞™‡±ç‡∞∞‡∞Ø‡∞§‡±ç‡∞®‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.',
      'ta': '‡ÆÆ‡Æ©‡Øç‡Æ©‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç, ‡Æé‡Æ©‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡ØÅ‡Æ∞‡Æø‡ÆØ‡Æµ‡Æø‡Æ≤‡Øç‡Æ≤‡Øà. ‡Æ§‡ÆØ‡Æµ‡ØÅ‡Æö‡ØÜ‡ÆØ‡Øç‡Æ§‡ØÅ ‡ÆÆ‡ØÄ‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç ‡ÆÆ‡ØÅ‡ÆØ‡Æ±‡Øç‡Æö‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.',
      'mr': '‡§ï‡•ç‡§∑‡§Æ‡§∏‡•ç‡§µ, ‡§Æ‡§≤‡§æ ‡§∏‡§Æ‡§ú‡§≤‡•á ‡§®‡§æ‡§π‡•Ä. ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§™‡•ç‡§∞‡§Ø‡§§‡•ç‡§® ‡§ï‡§∞‡§æ.'
    };
    return errorMessages[language as keyof typeof errorMessages] || errorMessages['hi'];
  };

  const speakText = async (text: string, language: string, messageId: string) => {
    if (!synthRef.current || !audioEnabled) return;

    // Cancel any ongoing speech
    synthRef.current.cancel();

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = getLanguageCode(language);
    utterance.rate = 0.9;
    utterance.pitch = 1;
    utterance.volume = 1;

    utterance.onstart = () => {
      setIsPlaying(messageId);
    };

    utterance.onend = () => {
      setIsPlaying(null);
    };

    utterance.onerror = (event) => {
      console.error('Speech synthesis error:', event.error);
      setIsPlaying(null);
    };

    // Get available voices for the language
    const voices = synthRef.current.getVoices();
    const languageVoice = voices.find(voice => 
      voice.lang.startsWith(language === 'kn' ? 'kn' : language === 'te' ? 'te' : language === 'ta' ? 'ta' : language === 'mr' ? 'mr' : language === 'hi' ? 'hi' : 'en')
    );
    
    if (languageVoice) {
      utterance.voice = languageVoice;
    }

    synthRef.current.speak(utterance);
  };

  const addMessage = (type: 'user' | 'assistant', content: string, language: string): Message => {
    const message: Message = {
      id: Date.now().toString(),
      type,
      content,
      timestamp: new Date(),
      language
    };

    setMessages(prev => [...prev, message]);
    return message;
  };

  const playMessage = (messageId: string, content: string, language: string) => {
    if (isPlaying === messageId) {
      synthRef.current?.cancel();
      setIsPlaying(null);
    } else {
      speakText(content, language, messageId);
    }
  };

  const capturePhoto = async () => {
    const imageSrc = webcamRef.current?.getScreenshot();
    if (imageSrc) {
      try {
        setIsProcessing(true);
        
        // Convert base64 to file
        const response = await fetch(imageSrc);
        const blob = await response.blob();
        const file = new File([blob], 'crop-photo.jpg', { type: 'image/jpeg' });
        
        // Analyze with Gemini
        const analysisResult = await geminiService.analyzeCropDisease(file);
        
        // Create response message in selected language
        const responseText = formatDiseaseResponse(analysisResult, selectedLanguage);
        addMessage('assistant', responseText, selectedLanguage);
        
        // Speak the response
        if (audioEnabled) {
          await speakText(responseText, selectedLanguage, Date.now().toString());
        }
        
        setShowCamera(false);
      } catch (error) {
        console.error('Error analyzing crop photo:', error);
        const errorMessage = getErrorMessage(selectedLanguage);
        addMessage('assistant', errorMessage, selectedLanguage);
      } finally {
        setIsProcessing(false);
      }
    }
  };

  const formatDiseaseResponse = (result: any, language: string): string => {
    const responses = {
      'hi': `‡§Ü‡§™‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ${result.hindiName || result.disease} ‡§∞‡•ã‡§ó ‡§ï‡§æ ‡§™‡§§‡§æ ‡§ö‡§≤‡§æ ‡§π‡•à‡•§ ‡§ó‡§Ç‡§≠‡•Ä‡§∞‡§§‡§æ: ${result.severity}‡•§ ‡§â‡§™‡§ö‡§æ‡§∞: ${result.treatment?.[0] || '‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§ú‡•ç‡§û ‡§∏‡•á ‡§∏‡§≤‡§æ‡§π ‡§≤‡•á‡§Ç'}‡•§`,
      'en': `Your crop has ${result.disease}. Severity: ${result.severity}. Treatment: ${result.treatment?.[0] || 'Consult local agricultural expert'}.`,
      'kn': `‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤¨‡≥Ü‡≤≥‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø ${result.disease} ‡≤∞‡≥ã‡≤ó ‡≤ï‡≤Ç‡≤°‡≥Å‡≤¨‡≤Ç‡≤¶‡≤ø‡≤¶‡≥Ü. ‡≤§‡≥Ä‡≤µ‡≥ç‡≤∞‡≤§‡≥Ü: ${result.severity}. ‡≤ö‡≤ø‡≤ï‡≤ø‡≤§‡≥ç‡≤∏‡≥Ü: ${result.treatment?.[0] || '‡≤∏‡≥ç‡≤•‡≤≥‡≥Ä‡≤Ø ‡≤ï‡≥É‡≤∑‡≤ø ‡≤§‡≤ú‡≥ç‡≤û‡≤∞‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≤Ç‡≤™‡≤∞‡≥ç‡≤ï‡≤ø‡≤∏‡≤ø'}.`,
      'te': `‡∞Æ‡±Ä ‡∞™‡∞Ç‡∞ü‡∞≤‡±ã ${result.disease} ‡∞µ‡±ç‡∞Ø‡∞æ‡∞ß‡∞ø ‡∞ï‡∞®‡±Å‡∞ó‡±ä‡∞®‡∞¨‡∞°‡∞ø‡∞Ç‡∞¶‡∞ø. ‡∞§‡±Ä‡∞µ‡±ç‡∞∞‡∞§: ${result.severity}. ‡∞ö‡∞ø‡∞ï‡∞ø‡∞§‡±ç ‡∞∏: ${result.treatment?.[0] || '‡∞∏‡±ç‡∞•‡∞æ‡∞®‡∞ø‡∞ï ‡∞µ‡±ç‡∞Ø‡∞µ‡∞∏‡∞æ‡∞Ø ‡∞®‡∞ø‡∞™‡±Å‡∞£‡±Å‡∞≤‡∞®‡±Å ‡∞∏‡∞Ç‡∞™‡±ç‡∞∞‡∞¶‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø'}.`,
      'ta': `‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡ÆØ‡Æø‡Æ∞‡Æø‡Æ≤‡Øç ${result.disease} ‡Æ®‡Øã‡ÆØ‡Øç ‡Æï‡Æ£‡Øç‡Æü‡Æ±‡Æø‡ÆØ‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü‡Æ§‡ØÅ. ‡Æ§‡ØÄ‡Æµ‡Æø‡Æ∞‡ÆÆ‡Øç: ${result.severity}. ‡Æö‡Æø‡Æï‡Æø‡Æö‡Øç‡Æö‡Øà: ${result.treatment?.[0] || '‡Æâ‡Æ≥‡Øç‡Æ≥‡ØÇ‡Æ∞‡Øç ‡Æµ‡Æø‡Æµ‡Æö‡Ææ‡ÆØ ‡Æ®‡Æø‡Æ™‡ØÅ‡Æ£‡Æ∞‡Øà ‡ÆÖ‡Æ£‡ØÅ‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç'}.`,
      'mr': `‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§™‡§ø‡§ï‡§æ‡§§ ${result.disease} ‡§∞‡•ã‡§ó ‡§Ü‡§¢‡§≥‡§≤‡§æ ‡§Ü‡§π‡•á. ‡§§‡•Ä‡§µ‡•ç‡§∞‡§§‡§æ: ${result.severity}. ‡§â‡§™‡§ö‡§æ‡§∞: ${result.treatment?.[0] || '‡§∏‡•ç‡§•‡§æ‡§®‡§ø‡§ï ‡§ï‡•É‡§∑‡•Ä ‡§§‡§ú‡•ç‡§û‡§æ‡§Ç‡§ö‡§æ ‡§∏‡§≤‡•ç‡§≤‡§æ ‡§ò‡•ç‡§Ø‡§æ'}.`
    };
    
    return responses[language as keyof typeof responses] || responses['hi'];
  };

  const switchCamera = () => {
    setFacingMode(prev => prev === 'user' ? 'environment' : 'user');
  };

  const formatTime = (date: Date) => {
    return date.toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
  };

  return (
    <div className="max-w-4xl mx-auto p-6">
      <div className="bg-white rounded-lg shadow-lg overflow-hidden h-[700px] flex flex-col">
        {/* Header */}
        <div className="bg-green-700 text-white p-4 flex items-center justify-between">
          <div className="flex items-center">
            <MessageCircle className="h-6 w-6 mr-2" />
            <h2 className="text-xl font-bold">AI Voice Assistant</h2>
          </div>
          <div className="flex items-center space-x-2">
            <button
              onClick={() => setAudioEnabled(!audioEnabled)}
              className="p-2 rounded-full hover:bg-green-600 transition-colors"
            >
              {audioEnabled ? <Volume2 className="h-5 w-5" /> : <VolumeX className="h-5 w-5" />}
            </button>
            <button
              onClick={() => setShowCamera(true)}
              className="p-2 rounded-full hover:bg-green-600 transition-colors"
              title="Crop Disease Detection"
            >
              <Camera className="h-5 w-5" />
            </button>
          </div>
        </div>

        {/* Language Selection */}
        <div className="bg-green-50 p-4 border-b">
          <div className="flex items-center mb-2">
            <Languages className="h-5 w-5 text-green-600 mr-2" />
            <span className="text-sm font-medium text-gray-700">Select Language / ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç</span>
          </div>
          <div className="flex flex-wrap gap-2">
            {languages.map((lang) => (
              <button
                key={lang.code}
                onClick={() => setSelectedLanguage(lang.code)}
                className={`px-3 py-1 rounded-full text-sm font-medium transition-colors ${
                  selectedLanguage === lang.code
                    ? 'bg-green-600 text-white'
                    : 'bg-white text-gray-700 hover:bg-green-100 border border-gray-300'
                }`}
              >
                {lang.flag} {lang.name}
              </button>
            ))}
          </div>
        </div>

        {/* Messages */}
        <div className="flex-1 overflow-y-auto p-4 space-y-4">
          {messages.length === 0 && (
            <div className="text-center text-gray-500 mt-8">
              <MessageCircle className="h-12 w-12 mx-auto mb-4 text-gray-300" />
              <p className="mb-2">Start speaking in {getLanguageName(selectedLanguage)}</p>
              <p className="text-sm">{getLanguageName(selectedLanguage)} ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤‡§®‡§æ ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç</p>
              <div className="mt-4 text-xs text-gray-400">
                <p>Ask about: crop diseases, market prices, farming tips</p>
                <p>‡§™‡•Ç‡§õ‡•á‡§Ç: ‡§´‡§∏‡§≤ ‡§∞‡•ã‡§ó, ‡§¨‡§æ‡§ú‡§æ‡§∞ ‡§≠‡§æ‡§µ, ‡§ñ‡•á‡§§‡•Ä ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π</p>
              </div>
            </div>
          )}

          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
            >
              <div
                className={`max-w-xs lg:max-w-md px-4 py-2 rounded-lg ${
                  message.type === 'user'
                    ? 'bg-green-600 text-white'
                    : 'bg-gray-100 text-gray-900'
                }`}
              >
                <p className="text-sm">{message.content}</p>
                <div className="flex items-center justify-between mt-2">
                  <span className="text-xs opacity-75">
                    {formatTime(message.timestamp)} ‚Ä¢ {getLanguageName(message.language || selectedLanguage)}
                  </span>
                  {message.type === 'assistant' && audioEnabled && (
                    <button
                      onClick={() => playMessage(message.id, message.content, message.language || selectedLanguage)}
                      className="ml-2 p-1 rounded hover:bg-gray-200 transition-colors"
                    >
                      {isPlaying === message.id ? (
                        <Pause className="h-3 w-3" />
                      ) : (
                        <Play className="h-3 w-3" />
                      )}
                    </button>
                  )}
                </div>
              </div>
            </div>
          ))}

          {isProcessing && (
            <div className="flex justify-start">
              <div className="bg-gray-100 text-gray-900 max-w-xs lg:max-w-md px-4 py-2 rounded-lg">
                <div className="flex items-center">
                  <Loader className="h-4 w-4 animate-spin mr-2" />
                  <span className="text-sm">Processing in {getLanguageName(selectedLanguage)}...</span>
                </div>
              </div>
            </div>
          )}
        </div>

        {/* Voice Input Controls */}
        <div className="p-4 border-t border-gray-200">
          <div className="flex items-center justify-center">
            <button
              onClick={isRecording ? stopVoiceRecording : startVoiceRecording}
              disabled={isProcessing}
              className={`p-4 rounded-full transition-all duration-200 ${
                isRecording
                  ? 'bg-red-600 hover:bg-red-700 animate-pulse'
                  : 'bg-green-600 hover:bg-green-700'
              } ${isProcessing ? 'opacity-50 cursor-not-allowed' : ''}`}
            >
              {isRecording ? (
                <MicOff className="h-8 w-8 text-white" />
              ) : (
                <Mic className="h-8 w-8 text-white" />
              )}
            </button>
          </div>
          <p className="text-center text-sm text-gray-500 mt-2">
            {isRecording 
              ? `Recording in ${getLanguageName(selectedLanguage)}... Tap to stop`
              : `Tap to speak in ${getLanguageName(selectedLanguage)}`
            }
          </p>
        </div>

        {/* Quick Actions */}
        <div className="p-4 bg-gray-50 border-t border-gray-200">
          <p className="text-xs text-gray-500 mb-2">Quick questions / ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§™‡•ç‡§∞‡§∂‡•ç‡§®:</p>
          <div className="flex flex-wrap gap-2">
            {[
              { en: 'What disease does my crop have?', hi: '‡§Æ‡•á‡§∞‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§ï‡•å‡§® ‡§∏‡§æ ‡§∞‡•ã‡§ó ‡§π‡•à?' },
              { en: 'Current wheat prices', hi: '‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡§æ ‡§µ‡§∞‡•ç‡§§‡§Æ‡§æ‡§® ‡§≠‡§æ‡§µ' },
              { en: 'Government schemes for farmers', hi: '‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Ç' },
              { en: 'Weather forecast', hi: '‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä' }
            ].map((question, index) => (
              <button
                key={index}
                className="px-3 py-1 bg-white border border-gray-200 rounded-full text-xs text-gray-600 hover:bg-gray-100 transition-colors"
                onClick={() => {
                  const text = selectedLanguage === 'hi' ? question.hi : question.en;
                  processVoiceQuery(text);
                }}
              >
                {selectedLanguage === 'hi' ? question.hi : question.en}
              </button>
            ))}
          </div>
        </div>
      </div>

      {/* Camera Modal */}
      {showCamera && (
        <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
          <div className="bg-white rounded-lg p-6 max-w-md w-full mx-4">
            <div className="flex justify-between items-center mb-4">
              <h3 className="text-lg font-semibold">Crop Disease Detection</h3>
              <div className="flex items-center space-x-2">
                <button
                  onClick={switchCamera}
                  className="p-2 bg-gray-100 rounded-full hover:bg-gray-200"
                  title="Switch Camera"
                >
                  <SwitchCamera className="h-5 w-5" />
                </button>
                <button
                  onClick={() => setShowCamera(false)}
                  className="text-gray-500 hover:text-gray-700"
                >
                  ‚úï
                </button>
              </div>
            </div>
            
            <Webcam
              ref={webcamRef}
              screenshotFormat="image/jpeg"
              videoConstraints={{
                facingMode: facingMode
              }}
              className="w-full rounded-lg mb-4"
            />
            
            <div className="flex justify-between">
              <button
                onClick={() => setShowCamera(false)}
                className="px-4 py-2 text-gray-600 hover:text-gray-800"
              >
                Cancel
              </button>
              <button
                onClick={capturePhoto}
                disabled={isProcessing}
                className="px-4 py-2 bg-green-600 text-white rounded-md hover:bg-green-700 disabled:opacity-50"
              >
                {isProcessing ? 'Analyzing...' : 'Capture & Analyze'}
              </button>
            </div>
          </div>
        </div>
      )}
    </div>
  );
};

export default VoiceAssistant;